{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import time\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "np.random.seed(1337)\n",
    "df = pd.read_csv('train.csv') \n",
    "df = df.drop(['Name','Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna() # drop rows with missing ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  \\\n",
       "0            1         0       3  22.0      1      0   7.2500           0   \n",
       "1            2         1       1  38.0      1      0  71.2833           1   \n",
       "2            3         1       3  26.0      0      0   7.9250           1   \n",
       "3            4         1       1  35.0      1      0  53.1000           1   \n",
       "4            5         0       3  35.0      0      0   8.0500           0   \n",
       "\n",
       "   Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         1           0           0           1  \n",
       "1         0           1           0           0  \n",
       "2         0           0           0           1  \n",
       "3         0           0           0           1  \n",
       "4         1           0           0           1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To convert categorical data to numerical data, a few different ways.\n",
    "\n",
    "# 1.\n",
    "# df['Sex'] = df['Sex'].map({'female':0, 'male':1}) # change sex to integer values\n",
    "\n",
    "# 2.\n",
    "# embarked_sex = pd.get_dummies(df.Sex, prefix=\"Sex\").iloc[:,1:] # change Sex to Sex_male\n",
    "# embarked_dummies = pd.get_dummies(df.Embarked, prefix=\"Embarked\").iloc[:, 1:] # Embarked_S, Embarked_Q\n",
    "\n",
    "# concat back to original data frame.\n",
    "# pd = pd.concat([df, embarked_sex], axis = 1)\n",
    "# pd = pd.concat([df, embarked_dummies], axis = 1)\n",
    "\n",
    "# 3.\n",
    "# A better way:\n",
    "df = pd.get_dummies(df, columns = ['Sex', 'Embarked'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 80% rows for training and 20% rows for testing.\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = df[msk]\n",
    "test = df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lingxiwu/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/Users/lingxiwu/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/lingxiwu/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Normalize features to the same scale.\n",
    "scaler = StandardScaler()\n",
    "features = ['Pclass','Sex_female','Sex_male','Age','SibSp','Parch','Fare','Embarked_C','Embarked_Q','Embarked_S']\n",
    "\n",
    "X_train = scaler.fit_transform(train[features].values)\n",
    "Y_train = scaler.fit_transform(train['Survived'].values)\n",
    "y_train_onehot = pd.get_dummies(train['Survived']).values\n",
    "\n",
    "X_test = scaler.transform(test[features].values)\n",
    "y_test = test['Survived'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lingxiwu/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=10, units=100)`\n",
      "  \n",
      "/Users/lingxiwu/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=100)`\n",
      "  import sys\n",
      "/Users/lingxiwu/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=2)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "582/582 [==============================] - 0s - loss: 0.5224 - acc: 0.7784     \n",
      "Epoch 2/10\n",
      "582/582 [==============================] - 0s - loss: 0.4650 - acc: 0.7869     \n",
      "Epoch 3/10\n",
      "582/582 [==============================] - 0s - loss: 0.4522 - acc: 0.7904     \n",
      "Epoch 4/10\n",
      "582/582 [==============================] - 0s - loss: 0.4469 - acc: 0.7990     \n",
      "Epoch 5/10\n",
      "582/582 [==============================] - 0s - loss: 0.4434 - acc: 0.8024     \n",
      "Epoch 6/10\n",
      "582/582 [==============================] - 0s - loss: 0.4424 - acc: 0.8041     \n",
      "Epoch 7/10\n",
      "582/582 [==============================] - 0s - loss: 0.4404 - acc: 0.8041     \n",
      "Epoch 8/10\n",
      "582/582 [==============================] - 0s - loss: 0.4390 - acc: 0.8007     \n",
      "Epoch 9/10\n",
      "582/582 [==============================] - 0s - loss: 0.4385 - acc: 0.8058     \n",
      "Epoch 10/10\n",
      "582/582 [==============================] - 0s - loss: 0.4382 - acc: 0.8041     \n",
      " 32/130 [======>.......................] - ETA: 0s\n",
      "\n",
      "accuracy 0.730769230769\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "start = time()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=10, output_dim=100))\n",
    "model.add(Dense(output_dim=100))\n",
    "model.add(Dense(output_dim=2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_onehot)\n",
    "\n",
    "# print('\\ntime taken %s seconds' % str(time() - start))\n",
    "\n",
    "y_prediction = model.predict_classes(X_test)\n",
    "print(\"\\n\\naccuracy\", np.sum(y_prediction == y_test) / float(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 x 5 cross validation ...\n",
      "------ Round 1 ------\n",
      "Training Phase ...\n",
      "Training Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lingxiwu/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/Users/lingxiwu/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/lingxiwu/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/lingxiwu/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=10, units=100)`\n",
      "/Users/lingxiwu/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=100)`\n",
      "/Users/lingxiwu/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:43: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('5 x 5 cross validation ...')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = df[features]\n",
    "y = df['Survived']\n",
    "\n",
    "models = [] # to hold all the temporary models.\n",
    "model_scores = [] # to hold the accuracy scores \n",
    "\n",
    "i = 0\n",
    "skf = StratifiedKFold(n_splits=5, random_state=1234)\n",
    "for train_indices_out, test_indices_out in skf.split(X, y):\n",
    "    \n",
    "    i+=1\n",
    "    # train/test split - outer loop.\n",
    "    X_train_out = X.iloc[train_indices_out] \n",
    "    y_train_out = y.iloc[train_indices_out]\n",
    "    \n",
    "    X_test_out = X.iloc[test_indices_out]\n",
    "    y_test_out = y.iloc[test_indices_out]\n",
    "    \n",
    "    print(\"------ Round {} ------\".format(i))\n",
    "    \n",
    "    j = 0\n",
    "    print(\"Training Phase ...\")\n",
    "    for train_indices_in, test_indices_in in skf.split(X_train_out, y_train_out):\n",
    "        \n",
    "        print('Training Model {}'.format(j+1))\n",
    "       \n",
    "        j += 1\n",
    "        # train/test split - inner loop.\n",
    "        X_train_in = scaler.fit_transform(X_train_out.iloc[train_indices_in].values)\n",
    "        y_train_in = scaler.fit_transform(y_train_out.iloc[train_indices_in].values)\n",
    "        y_train_in_onehot = pd.get_dummies(y_train_out.iloc[train_indices_in]).values\n",
    "        \n",
    "        X_test_in = scaler.transform(X_train_out.iloc[test_indices_in].values)\n",
    "        y_test_in = y_train_out.iloc[test_indices_in]\n",
    "       \n",
    "        model = Sequential()\n",
    "        model.add(Dense(input_dim=10, output_dim=100))\n",
    "        model.add(Dense(output_dim=100))\n",
    "        model.add(Dense(output_dim=2))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "        \n",
    "        model.fit(X_train_in, y_train_in_onehot)\n",
    "        \n",
    "        # Add to the model list.\n",
    "        models.append(model)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred_in = model.predict_classes(X_test_in)\n",
    "\n",
    "        # Show results\n",
    "        accuracy_in = accuracy_score(y_test_in, y_pred_in)\n",
    "        cm_in = classification_report(y_test_in, y_pred_in)\n",
    "\n",
    "        model_scores.append(accuracy_in)       \n",
    "               \n",
    "        print('\\nTraining Accuracy: {}'.format(accuracy_in))\n",
    "        print('\\nTraining CM: \\n',cm_in)\n",
    "        \n",
    "    # Retrieve the index of the model with highest score.\n",
    "    highest_score_index = model_scores.index(max(model_scores))\n",
    "    print('Best Model is: {}'.format(highest_score_index+1))\n",
    "    # Retrieve that model.\n",
    "    best_model = models[highest_score_index]\n",
    "    \n",
    "    \n",
    "    # Predict on best model on this round.\n",
    "    y_pred_out = best_model.predict_classes(scaler.transform(X.iloc[test_indices_out].values))\n",
    "    \n",
    "    # Show results\n",
    "    accuracy_out = accuracy_score(y_test_out, y_pred_out)\n",
    "    cm_out = classification_report(y_test_out, y_pred_out)\n",
    "    \n",
    "    \n",
    "    print(\"\\nTesting Accuracy round {}: {}\".format(i, accuracy_out))\n",
    "    print(cm_out)\n",
    "    \n",
    "    # empty results for the next round of execution.\n",
    "    models = [] \n",
    "    model_scores = [] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
